{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_path = Path(r'C:\\Users\\gabri\\OneDrive\\Documents\\VMBoxShared\\abr_jul_2024\\Miniproyecto\\plain-text-to-rdf\\test\\.env')\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "CORENLP_DIR = os.environ.get('CORENLP_HOME')\n",
    "CORENLP_DIR = r'C:\\Users\\gabri\\OneDrive\\Documents\\VMBoxShared\\abr_jul_2024\\Miniproyecto\\plain-text-to-rdf\\corenlp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 16:38:21 WARNING: Directory C:\\Users\\gabri\\OneDrive\\Documents\\VMBoxShared\\abr_jul_2024\\Miniproyecto\\plain-text-to-rdf\\corenlp already exists. Please install CoreNLP to a new directory.\n",
      "2024-05-22 16:38:21 INFO: Downloading english-kbp models (version main) into directory C:\\Users\\gabri\\OneDrive\\Documents\\VMBoxShared\\abr_jul_2024\\Miniproyecto\\plain-text-to-rdf\\corenlp\n",
      "Downloading https://huggingface.co/stanfordnlp/corenlp-english-kbp/resolve/main/stanford-corenlp-models-english-kbp.jar: 100%|██████████| 227M/227M [05:47<00:00, 655kB/s] \n",
      "2024-05-22 16:44:10 INFO: Downloaded file to C:\\Users\\gabri\\OneDrive\\Documents\\VMBoxShared\\abr_jul_2024\\Miniproyecto\\plain-text-to-rdf\\corenlp\\stanford-corenlp-main-models-english-kbp.jar\n"
     ]
    }
   ],
   "source": [
    "stanza.download_corenlp_models(model='english-kbp', dir=CORENLP_DIR, version='main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 00:32:12 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 4.70MB/s]                    \n",
      "2024-05-23 00:32:12 INFO: Downloaded file to C:\\Users\\gabri\\stanza_resources\\resources.json\n",
      "2024-05-23 00:32:14 INFO: Loading these models for language: en (English):\n",
      "============================================\n",
      "| Processor    | Package                   |\n",
      "--------------------------------------------\n",
      "| tokenize     | combined                  |\n",
      "| mwt          | combined                  |\n",
      "| pos          | combined_charlm           |\n",
      "| lemma        | combined_nocharlm         |\n",
      "| constituency | ptb3-revised_charlm       |\n",
      "| depparse     | combined_charlm           |\n",
      "| sentiment    | sstplus_charlm            |\n",
      "| ner          | ontonotes-ww-multi_charlm |\n",
      "============================================\n",
      "\n",
      "2024-05-23 00:32:14 INFO: Using device: cpu\n",
      "2024-05-23 00:32:14 INFO: Loading: tokenize\n",
      "2024-05-23 00:32:14 INFO: Loading: mwt\n",
      "2024-05-23 00:32:14 INFO: Loading: pos\n",
      "2024-05-23 00:32:14 INFO: Loading: lemma\n",
      "2024-05-23 00:32:14 INFO: Loading: constituency\n",
      "2024-05-23 00:32:15 INFO: Loading: depparse\n",
      "2024-05-23 00:32:16 INFO: Loading: sentiment\n",
      "2024-05-23 00:32:16 INFO: Loading: ner\n",
      "2024-05-23 00:32:17 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo para procesar el texto: 2.2392 segundos\n",
      "\n",
      "Tokens y Etiquetas:\n",
      "Token: The\n",
      "  Lemma: the\n",
      "  POS: DET\n",
      "  XPOS: DT\n",
      "  Head: 4\n",
      "  Deprel: det\n",
      "Token: quick\n",
      "  Lemma: quick\n",
      "  POS: ADJ\n",
      "  XPOS: JJ\n",
      "  Head: 4\n",
      "  Deprel: amod\n",
      "Token: brown\n",
      "  Lemma: brown\n",
      "  POS: ADJ\n",
      "  XPOS: JJ\n",
      "  Head: 4\n",
      "  Deprel: amod\n",
      "Token: fox\n",
      "  Lemma: fox\n",
      "  POS: NOUN\n",
      "  XPOS: NN\n",
      "  Head: 17\n",
      "  Deprel: nsubj\n",
      "Token: ,\n",
      "  Lemma: ,\n",
      "  POS: PUNCT\n",
      "  XPOS: ,\n",
      "  Head: 9\n",
      "  Deprel: punct\n",
      "Token: which\n",
      "  Lemma: which\n",
      "  POS: PRON\n",
      "  XPOS: WDT\n",
      "  Head: 9\n",
      "  Deprel: nsubj:pass\n",
      "Token: was\n",
      "  Lemma: be\n",
      "  POS: AUX\n",
      "  XPOS: VBD\n",
      "  Head: 9\n",
      "  Deprel: aux\n",
      "Token: being\n",
      "  Lemma: be\n",
      "  POS: AUX\n",
      "  XPOS: VBG\n",
      "  Head: 9\n",
      "  Deprel: aux:pass\n",
      "Token: chased\n",
      "  Lemma: chase\n",
      "  POS: VERB\n",
      "  XPOS: VBN\n",
      "  Head: 4\n",
      "  Deprel: acl:relcl\n",
      "Token: by\n",
      "  Lemma: by\n",
      "  POS: ADP\n",
      "  XPOS: IN\n",
      "  Head: 15\n",
      "  Deprel: case\n",
      "Token: a\n",
      "  Lemma: a\n",
      "  POS: DET\n",
      "  XPOS: DT\n",
      "  Head: 15\n",
      "  Deprel: det\n",
      "Token: cunning\n",
      "  Lemma: cunning\n",
      "  POS: ADJ\n",
      "  XPOS: JJ\n",
      "  Head: 15\n",
      "  Deprel: amod\n",
      "Token: and\n",
      "  Lemma: and\n",
      "  POS: CCONJ\n",
      "  XPOS: CC\n",
      "  Head: 14\n",
      "  Deprel: cc\n",
      "Token: agile\n",
      "  Lemma: agile\n",
      "  POS: ADJ\n",
      "  XPOS: JJ\n",
      "  Head: 12\n",
      "  Deprel: conj\n",
      "Token: hound\n",
      "  Lemma: hound\n",
      "  POS: NOUN\n",
      "  XPOS: NN\n",
      "  Head: 9\n",
      "  Deprel: obl\n",
      "Token: ,\n",
      "  Lemma: ,\n",
      "  POS: PUNCT\n",
      "  XPOS: ,\n",
      "  Head: 4\n",
      "  Deprel: punct\n",
      "Token: jumped\n",
      "  Lemma: jump\n",
      "  POS: VERB\n",
      "  XPOS: VBD\n",
      "  Head: 0\n",
      "  Deprel: root\n",
      "Token: over\n",
      "  Lemma: over\n",
      "  POS: ADP\n",
      "  XPOS: IN\n",
      "  Head: 21\n",
      "  Deprel: case\n",
      "Token: the\n",
      "  Lemma: the\n",
      "  POS: DET\n",
      "  XPOS: DT\n",
      "  Head: 21\n",
      "  Deprel: det\n",
      "Token: lazy\n",
      "  Lemma: lazy\n",
      "  POS: ADJ\n",
      "  XPOS: JJ\n",
      "  Head: 21\n",
      "  Deprel: amod\n",
      "Token: dog\n",
      "  Lemma: dog\n",
      "  POS: NOUN\n",
      "  XPOS: NN\n",
      "  Head: 17\n",
      "  Deprel: obl\n",
      "Token: lying\n",
      "  Lemma: lie\n",
      "  POS: VERB\n",
      "  XPOS: VBG\n",
      "  Head: 21\n",
      "  Deprel: acl\n",
      "Token: near\n",
      "  Lemma: near\n",
      "  POS: ADP\n",
      "  XPOS: IN\n",
      "  Head: 25\n",
      "  Deprel: case\n",
      "Token: the\n",
      "  Lemma: the\n",
      "  POS: DET\n",
      "  XPOS: DT\n",
      "  Head: 25\n",
      "  Deprel: det\n",
      "Token: barn\n",
      "  Lemma: barn\n",
      "  POS: NOUN\n",
      "  XPOS: NN\n",
      "  Head: 22\n",
      "  Deprel: obl\n",
      "Token: .\n",
      "  Lemma: .\n",
      "  POS: PUNCT\n",
      "  XPOS: .\n",
      "  Head: 17\n",
      "  Deprel: punct\n",
      "Tiempo para extraer y mostrar tokens y etiquetas: 0.0020 segundos\n",
      "\n",
      "Árbol de Dependencias:\n",
      "                                                                                                      jumped                                                                                                         \n",
      "                                                                  ______________________________________|_______________________________________________________________________________________________________      \n",
      "                                                            fox (nsubj)                                                                                            |                                            |    \n",
      "     ____________________________________________________________|________________________________________________________________                                 |                                            |     \n",
      "    |          |            |                                             chased (acl:                                            |                                |                                            |    \n",
      "    |          |            |                                                relcl)                                               |                                |                                            |    \n",
      "    |          |            |            ______________________________________|________________________                          |                                |                                            |     \n",
      "    |          |            |           |           |            |             |                   hound (obl)                    |                            dog (obl)                                        |    \n",
      "    |          |            |           |           |            |             |              __________|____________             |           _____________________|_______________________                     |     \n",
      "    |          |            |           |           |            |             |             |          |      cunning (amod)     |          |          |          |                  lying (acl)               |    \n",
      "    |          |            |           |           |            |             |             |          |            |            |          |          |          |                       |                    |     \n",
      "    |          |            |           |           |            |             |             |          |       agile (conj)      |          |          |          |                   barn (obl)               |    \n",
      "    |          |            |           |           |            |             |             |          |            |            |          |          |          |            ___________|__________          |     \n",
      "The (det) quick (amod) brown (amod) , (punct) which (nsubj:  was (aux)  being (aux:pass) by (case)   a (det)      and (cc)    , (punct) over (case) the (det) lazy (amod) near (case)             the (det) . (punct)\n",
      "    |          |            |           |         pass)          |             |             |          |            |            |          |          |          |           |                      |         |    \n",
      "    |          |            |           |           |            |             |             |          |            |            |          |          |          |           |                      |         |     \n",
      "   ...        ...          ...         ...         ...          ...           ...           ...        ...          ...          ...        ...        ...        ...         ...                    ...       ...   \n",
      "\n",
      "Tiempo para convertir a árbol y dibujar: 0.0042 segundos\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "import nltk\n",
    "from nltk.tree import Tree\n",
    "import time\n",
    "\n",
    "# Crear el pipeline de procesamiento\n",
    "nlp = stanza.Pipeline('en')\n",
    "\n",
    "# Texto a procesar\n",
    "plain_text = \"The quick brown fox, which was being chased by a cunning and agile hound, jumped over the lazy dog lying near the barn.\"\n",
    "\n",
    "# Medir el tiempo de procesamiento del texto\n",
    "start_time = time.time()\n",
    "doc = nlp(plain_text)\n",
    "end_time = time.time()\n",
    "print(f\"Tiempo para procesar el texto: {end_time - start_time:.4f} segundos\")\n",
    "\n",
    "# Mostrar los tokens y etiquetas\n",
    "print(\"\\nTokens y Etiquetas:\")\n",
    "start_time = time.time()\n",
    "for i, sentence in enumerate(doc.sentences):\n",
    "    for token in sentence.tokens:\n",
    "        print(f\"Token: {token.text}\")\n",
    "        for word in token.words:\n",
    "            print(f\"  Lemma: {word.lemma}\")      # Lema de la palabra\n",
    "            print(f\"  POS: {word.pos}\")          # Categoría gramatical universal\n",
    "            print(f\"  XPOS: {word.xpos}\")        # Categoría gramatical específica del idioma\n",
    "            print(f\"  Head: {word.head}\")        # Índice del \"head\" en el árbol de dependencias\n",
    "            print(f\"  Deprel: {word.deprel}\\n\")    # Relación de dependencia con el \"head\"\n",
    "end_time = time.time()\n",
    "print(f\"Tiempo para extraer y mostrar tokens y etiquetas: {end_time - start_time:.4f} segundos\")\n",
    "\n",
    "# Función para crear un árbol de dependencias\n",
    "def to_nltk_tree(node, doc):\n",
    "    if node.deprel == 'root':\n",
    "        return Tree(node.text, [to_nltk_tree(child, doc) for child in doc.sentences[0].words if child.head == node.id])\n",
    "    else:\n",
    "        return Tree(f'{node.text} ({node.deprel})', [to_nltk_tree(child, doc) for child in doc.sentences[0].words if child.head == node.id])\n",
    "\n",
    "# Dibujar el árbol de dependencias\n",
    "print(\"\\nÁrbol de Dependencias:\")\n",
    "start_time = time.time()\n",
    "for sentence in doc.sentences:\n",
    "    root = [word for word in sentence.words if word.head == 0][0]\n",
    "    tree = to_nltk_tree(root, doc)\n",
    "    tree.pretty_print()\n",
    "end_time = time.time()\n",
    "print(f\"Tiempo para convertir a árbol y dibujar: {end_time - start_time:.4f} segundos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
